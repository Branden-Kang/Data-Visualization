{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQoOcKabOZNs1hr7ef8L17"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://towardsdatascience.com/a-python-tool-for-fetching-air-pollution-data-from-google-maps-air-quality-apis-7cf58a7c63cb)"
      ],
      "metadata": {
        "id": "2o-PfBR2TCXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get the current air quality at a given location"
      ],
      "metadata": {
        "id": "Iv8c6PokUJHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "flBHxqptS-df"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "def load_secets():\n",
        "    load_dotenv()\n",
        "    env_path = Path(\".\") / \".env\"\n",
        "    load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "    google_maps_key = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
        "\n",
        "    return {\n",
        "        \"GOOGLE_MAPS_API_KEY\": google_maps_key,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "\n",
        "class Client(object):\n",
        "    DEFAULT_BASE_URL = \"https://airquality.googleapis.com\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "        self.session = requests.Session()\n",
        "        self.key = key\n",
        "\n",
        "    def request_post(self, url, params):\n",
        "        request_url = self.compose_url(url)\n",
        "        request_header = self.compose_header()\n",
        "        request_body = params\n",
        "\n",
        "        response = self.session.post(\n",
        "            request_url,\n",
        "            headers=request_header,\n",
        "            json=request_body,\n",
        "        )\n",
        "\n",
        "        return self.get_body(response)\n",
        "\n",
        "    def compose_url(self, path):\n",
        "        return self.DEFAULT_BASE_URL + path + \"?\" + \"key=\" + self.key\n",
        "\n",
        "    @staticmethod\n",
        "    def get_body(response):\n",
        "        body = response.json()\n",
        "\n",
        "        if \"error\" in body:\n",
        "            return body[\"error\"]\n",
        "\n",
        "        return body\n",
        "\n",
        "    @staticmethod\n",
        "    def compose_header():\n",
        "        return {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }"
      ],
      "metadata": {
        "id": "xHCfRm9jTL8I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def current_conditions(\n",
        "    client,\n",
        "    location,\n",
        "    include_local_AQI=True,\n",
        "    include_health_suggestion=False,\n",
        "    include_all_pollutants=True,\n",
        "    include_additional_pollutant_info=False,\n",
        "    include_dominent_pollutant_conc=True,\n",
        "    language=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    See documentation for this API here\n",
        "    https://developers.google.com/maps/documentation/air-quality/reference/rest/v1/currentConditions/lookup\n",
        "    \"\"\"\n",
        "    params = {}\n",
        "\n",
        "    if isinstance(location, dict):\n",
        "        params[\"location\"] = location\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Location argument must be a dictionary containing latitude and longitude\"\n",
        "        )\n",
        "\n",
        "    extra_computations = []\n",
        "    if include_local_AQI:\n",
        "        extra_computations.append(\"LOCAL_AQI\")\n",
        "\n",
        "    if include_health_suggestion:\n",
        "        extra_computations.append(\"HEALTH_RECOMMENDATIONS\")\n",
        "\n",
        "    if include_additional_pollutant_info:\n",
        "        extra_computations.append(\"POLLUTANT_ADDITIONAL_INFO\")\n",
        "\n",
        "    if include_all_pollutants:\n",
        "        extra_computations.append(\"POLLUTANT_CONCENTRATION\")\n",
        "\n",
        "    if include_dominent_pollutant_conc:\n",
        "        extra_computations.append(\"DOMINANT_POLLUTANT_CONCENTRATION\")\n",
        "\n",
        "    if language:\n",
        "        params[\"language\"] = language\n",
        "\n",
        "    params[\"extraComputations\"] = extra_computations\n",
        "\n",
        "    return client.request_post(\"/v1/currentConditions:lookup\", params)"
      ],
      "metadata": {
        "id": "fiyj7pvdTNUr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up client\n",
        "client = Client(key=GOOGLE_MAPS_API_KEY)\n",
        "# a location in Los Angeles, CA\n",
        "location = {\"longitude\":-118.3,\"latitude\":34.1}\n",
        "# a JSON response\n",
        "current_conditions_data = current_conditions(\n",
        "  client,\n",
        "  location,\n",
        "  include_health_suggestion=True,\n",
        "  include_additional_pollutant_info=True\n",
        ")"
      ],
      "metadata": {
        "id": "0PzMsenoTP9q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Get a timeseries of air quality at a given location\n"
      ],
      "metadata": {
        "id": "UynvBDk4T85X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def request_post(self,url,params):\n",
        "\n",
        "    request_url = self.compose_url(url)\n",
        "    request_header = self.compose_header()\n",
        "    request_body = params\n",
        "\n",
        "    response = self.session.post(\n",
        "      request_url,\n",
        "      headers=request_header,\n",
        "      json=request_body,\n",
        "    )\n",
        "\n",
        "    response_body = self.get_body(response)\n",
        "\n",
        "    # put the first page in the response dictionary\n",
        "    page = 1\n",
        "    final_response = {\n",
        "        \"page_{}\".format(page) : response_body\n",
        "    }\n",
        "    # fetch all the pages if needed\n",
        "    while \"nextPageToken\" in response_body:\n",
        "      # call again with the next page's token\n",
        "      request_body.update({\n",
        "          \"pageToken\":response_body[\"nextPageToken\"]\n",
        "      })\n",
        "      response = self.session.post(\n",
        "          request_url,\n",
        "          headers=request_header,\n",
        "          json=request_body,\n",
        "      )\n",
        "      response_body = self.get_body(response)\n",
        "      page += 1\n",
        "      final_response[\"page_{}\".format(page)] = response_body\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "ucx-g_lxTTU5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def historical_conditions(\n",
        "    client,\n",
        "    location,\n",
        "    specific_time=None,\n",
        "    lag_time=None,\n",
        "    specific_period=None,\n",
        "    include_local_AQI=True,\n",
        "    include_health_suggestion=False,\n",
        "    include_all_pollutants=True,\n",
        "    include_additional_pollutant_info=False,\n",
        "    include_dominant_pollutant_conc=True,\n",
        "    language=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    See documentation for this API here https://developers.google.com/maps/documentation/air-quality/reference/rest/v1/history/lookup\n",
        "    \"\"\"\n",
        "    params = {}\n",
        "\n",
        "    if isinstance(location, dict):\n",
        "        params[\"location\"] = location\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Location argument must be a dictionary containing latitude and longitude\"\n",
        "        )\n",
        "\n",
        "    if isinstance(specific_period, dict) and not specific_time and not lag_time:\n",
        "        assert \"startTime\" in specific_period\n",
        "        assert \"endTime\" in specific_period\n",
        "\n",
        "        params[\"period\"] = specific_period\n",
        "\n",
        "    elif specific_time and not lag_time and not isinstance(specific_period, dict):\n",
        "        # note that time must be in the \"Zulu\" format\n",
        "        # e.g. datetime.datetime.strftime(datetime.datetime.now(),\"%Y-%m-%dT%H:%M:%SZ\")\n",
        "        params[\"dateTime\"] = specific_time\n",
        "\n",
        "    # lag periods in hours\n",
        "    elif lag_time and not specific_time and not isinstance(specific_period, dict):\n",
        "        params[\"hours\"] = lag_time\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Must provide specific_time, specific_period or lag_time arguments\"\n",
        "        )\n",
        "\n",
        "    extra_computations = []\n",
        "    if include_local_AQI:\n",
        "        extra_computations.append(\"LOCAL_AQI\")\n",
        "\n",
        "    if include_health_suggestion:\n",
        "        extra_computations.append(\"HEALTH_RECOMMENDATIONS\")\n",
        "\n",
        "    if include_additional_pollutant_info:\n",
        "        extra_computations.append(\"POLLUTANT_ADDITIONAL_INFO\")\n",
        "\n",
        "    if include_all_pollutants:\n",
        "        extra_computations.append(\"POLLUTANT_CONCENTRATION\")\n",
        "\n",
        "    if include_dominant_pollutant_conc:\n",
        "        extra_computations.append(\"DOMINANT_POLLUTANT_CONCENTRATION\")\n",
        "\n",
        "    if language:\n",
        "        params[\"language\"] = language\n",
        "\n",
        "    params[\"extraComputations\"] = extra_computations\n",
        "    # page size default set to 100 here\n",
        "    params[\"pageSize\"] = 100\n",
        "    # page token will get filled in if needed by the request_post method\n",
        "    params[\"pageToken\"] = \"\"\n",
        "\n",
        "    return client.request_post(\"/v1/history:lookup\", params)"
      ],
      "metadata": {
        "id": "eE-o-GfDTYOt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up client\n",
        "client = Client(key=GOOGLE_MAPS_API_KEY)\n",
        "# a location in Los Angeles, CA\n",
        "location = {\"longitude\":-118.3,\"latitude\":34.1}\n",
        "# a JSON response\n",
        "history_conditions_data = historical_conditions(\n",
        "    client,\n",
        "    location,\n",
        "    lag_time=720\n",
        ")"
      ],
      "metadata": {
        "id": "tRMhGra3TV_a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import pandas as pd\n",
        "\n",
        "def historical_conditions_to_df(response_dict):\n",
        "\n",
        "  chained_pages = list(chain(*[response_dict[p][\"hoursInfo\"] for p in [*response_dict]]))\n",
        "\n",
        "  all_indexes = []\n",
        "  all_pollutants = []\n",
        "  for i in range(len(chained_pages)):\n",
        "    # need this check in case one of the timestamps is missing data, which can sometimes happen\n",
        "    if \"indexes\" in chained_pages[i]:\n",
        "      this_element = chained_pages[i]\n",
        "      # fetch the time\n",
        "      time = this_element[\"dateTime\"]\n",
        "      # fetch all the index values and add metadata\n",
        "      all_indexes += [(time , x[\"code\"],x[\"displayName\"],\"index\",x[\"aqi\"],None) for x in this_element['indexes']]\n",
        "      # fetch all the pollutant values and add metadata\n",
        "      all_pollutants += [(time , x[\"code\"],x[\"fullName\"],\"pollutant\",x[\"concentration\"][\"value\"],x[\"concentration\"][\"units\"]) for x in this_element['pollutants']]\n",
        "\n",
        "  all_results = all_indexes + all_pollutants\n",
        "  # generate \"long format\" dataframe\n",
        "  res = pd.DataFrame(all_results,columns=[\"time\",\"code\",\"name\",\"type\",\"value\",\"unit\"])\n",
        "  res[\"time\"]=pd.to_datetime(res[\"time\"])\n",
        "  return res\n",
        "\n",
        "df = historical_conditions_to_df(history_conditions_data)\n",
        "\n",
        "import seaborn as sns\n",
        "g = sns.relplot(\n",
        "    x=\"time\",\n",
        "    y=\"value\",\n",
        "    data=df[df[\"code\"].isin([\"uaqi\",\"usa_epa\",\"pm25\",\"pm10\"])],\n",
        "    kind=\"line\",\n",
        "    col=\"name\",\n",
        "    col_wrap=4,\n",
        "    hue=\"type\",\n",
        "    height=4,\n",
        "    facet_kws={'sharey': False, 'sharex': False}\n",
        ")\n",
        "g.set_xticklabels(rotation=90)"
      ],
      "metadata": {
        "id": "0PgkpOb0TbbQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Get air quality heatmap tiles"
      ],
      "metadata": {
        "id": "mJrbvQuUTluS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def request_get(self,url):\n",
        "\n",
        "    request_url = self.compose_url(url)\n",
        "    response = self.session.get(request_url)\n",
        "\n",
        "    # for images coming from the heatmap tiles service\n",
        "    return self.get_image(response)\n",
        "\n",
        "@staticmethod\n",
        "def get_image(response):\n",
        "    if response.status_code == 200:\n",
        "      image_content = response.content\n",
        "      # note use of Image from PIL here\n",
        "      # needs from PIL import Image\n",
        "      image = Image.open(io.BytesIO(image_content))\n",
        "      return image\n",
        "    else:\n",
        "      print(\"GET request for image returned an error\")\n",
        "      return None\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class TileHelper(object):\n",
        "\n",
        "  def __init__(self, tile_size=256):\n",
        "\n",
        "    self.tile_size = tile_size\n",
        "\n",
        "  def location_to_tile_xy(self,location,zoom_level=4):\n",
        "\n",
        "    # Based on function here\n",
        "    # https://developers.google.com/maps/documentation/javascript/examples/map-coordinates#maps_map_coordinates-javascript\n",
        "\n",
        "    lat = location[\"latitude\"]\n",
        "    lon = location[\"longitude\"]\n",
        "\n",
        "    world_coordinate = self._project(lat,lon)\n",
        "    scale = 1 << zoom_level\n",
        "\n",
        "    pixel_coord = (math.floor(world_coordinate[0]*scale), math.floor(world_coordinate[1]*scale))\n",
        "    tile_coord = (math.floor(world_coordinate[0]*scale/self.tile_size),math.floor(world_coordinate[1]*scale/self.tile_size))\n",
        "\n",
        "    return world_coordinate, pixel_coord, tile_coord\n",
        "\n",
        "  def tile_to_bounding_box(self,tx,ty,zoom_level):\n",
        "\n",
        "    # see https://developers.google.com/maps/documentation/javascript/coordinates\n",
        "    # for details\n",
        "    box_north = self._tiletolat(ty,zoom_level)\n",
        "    # tile numbers advance towards the south\n",
        "    box_south = self._tiletolat(ty+1,zoom_level)\n",
        "    box_west = self._tiletolon(tx,zoom_level)\n",
        "    # time numbers advance towards the east\n",
        "    box_east = self._tiletolon(tx+1,zoom_level)\n",
        "\n",
        "    # (latmin, latmax, lonmin, lonmax)\n",
        "    return (box_south, box_north, box_west, box_east)\n",
        "\n",
        "  @staticmethod\n",
        "  def _tiletolon(x,zoom):\n",
        "    return x / math.pow(2.0,zoom) * 360.0 - 180.0\n",
        "\n",
        "  @staticmethod\n",
        "  def _tiletolat(y,zoom):\n",
        "    n = math.pi - (2.0 * math.pi * y)/math.pow(2.0,zoom)\n",
        "    return math.atan(math.sinh(n))*(180.0/math.pi)\n",
        "\n",
        "  def _project(self,lat,lon):\n",
        "\n",
        "    siny = math.sin(lat*math.pi/180.0)\n",
        "    siny = min(max(siny,-0.9999), 0.9999)\n",
        "\n",
        "    return (self.tile_size*(0.5 + lon/360), self.tile_size*(0.5 - math.log((1 + siny) / (1 - siny)) / (4 * math.pi)))\n",
        "\n",
        "  @staticmethod\n",
        "  def find_nearest_corner(location,bounds):\n",
        "\n",
        "    corner_lat_idx = np.argmin([\n",
        "        np.abs(bounds[0]-location[\"latitude\"]),\n",
        "        np.abs(bounds[1]-location[\"latitude\"])\n",
        "        ])\n",
        "\n",
        "    corner_lon_idx = np.argmin([\n",
        "        np.abs(bounds[2]-location[\"longitude\"]),\n",
        "        np.abs(bounds[3]-location[\"longitude\"])\n",
        "        ])\n",
        "\n",
        "    if (corner_lat_idx == 0) and (corner_lon_idx == 0):\n",
        "      # closests is latmin, lonmin\n",
        "      direction = \"southwest\"\n",
        "    elif (corner_lat_idx == 0) and (corner_lon_idx == 1):\n",
        "      direction = \"southeast\"\n",
        "    elif (corner_lat_idx == 1) and (corner_lon_idx == 0):\n",
        "      direction = \"northwest\"\n",
        "    else:\n",
        "      direction = \"northeast\"\n",
        "\n",
        "    corner_coords = (bounds[corner_lat_idx],bounds[corner_lon_idx+2])\n",
        "    return corner_coords, direction\n",
        "\n",
        "  @staticmethod\n",
        "  def get_ajoining_tiles(tx,ty,direction):\n",
        "\n",
        "    if direction == \"southwest\":\n",
        "      return [(tx-1,ty),(tx-1,ty+1),(tx,ty+1)]\n",
        "    elif direction == \"southeast\":\n",
        "      return [(tx+1,ty),(tx+1,ty-1),(tx,ty-1)]\n",
        "    elif direction == \"northwest\":\n",
        "      return [(tx-1,ty-1),(tx-1,ty),(tx,ty-1)]\n",
        "    else:\n",
        "      return [(tx+1,ty-1),(tx+1,ty),(tx,ty-1)]"
      ],
      "metadata": {
        "id": "YtD70KeITi43"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class TileHelper(object):\n",
        "\n",
        "  def __init__(self, tile_size=256):\n",
        "\n",
        "    self.tile_size = tile_size\n",
        "\n",
        "  def location_to_tile_xy(self,location,zoom_level=4):\n",
        "\n",
        "    # Based on function here\n",
        "    # https://developers.google.com/maps/documentation/javascript/examples/map-coordinates#maps_map_coordinates-javascript\n",
        "\n",
        "    lat = location[\"latitude\"]\n",
        "    lon = location[\"longitude\"]\n",
        "\n",
        "    world_coordinate = self._project(lat,lon)\n",
        "    scale = 1 << zoom_level\n",
        "\n",
        "    pixel_coord = (math.floor(world_coordinate[0]*scale), math.floor(world_coordinate[1]*scale))\n",
        "    tile_coord = (math.floor(world_coordinate[0]*scale/self.tile_size),math.floor(world_coordinate[1]*scale/self.tile_size))\n",
        "\n",
        "    return world_coordinate, pixel_coord, tile_coord\n",
        "\n",
        "  def tile_to_bounding_box(self,tx,ty,zoom_level):\n",
        "\n",
        "    # see https://developers.google.com/maps/documentation/javascript/coordinates\n",
        "    # for details\n",
        "    box_north = self._tiletolat(ty,zoom_level)\n",
        "    # tile numbers advance towards the south\n",
        "    box_south = self._tiletolat(ty+1,zoom_level)\n",
        "    box_west = self._tiletolon(tx,zoom_level)\n",
        "    # time numbers advance towards the east\n",
        "    box_east = self._tiletolon(tx+1,zoom_level)\n",
        "\n",
        "    # (latmin, latmax, lonmin, lonmax)\n",
        "    return (box_south, box_north, box_west, box_east)\n",
        "\n",
        "  @staticmethod\n",
        "  def _tiletolon(x,zoom):\n",
        "    return x / math.pow(2.0,zoom) * 360.0 - 180.0\n",
        "\n",
        "  @staticmethod\n",
        "  def _tiletolat(y,zoom):\n",
        "    n = math.pi - (2.0 * math.pi * y)/math.pow(2.0,zoom)\n",
        "    return math.atan(math.sinh(n))*(180.0/math.pi)\n",
        "\n",
        "  def _project(self,lat,lon):\n",
        "\n",
        "    siny = math.sin(lat*math.pi/180.0)\n",
        "    siny = min(max(siny,-0.9999), 0.9999)\n",
        "\n",
        "    return (self.tile_size*(0.5 + lon/360), self.tile_size*(0.5 - math.log((1 + siny) / (1 - siny)) / (4 * math.pi)))\n",
        "\n",
        "  @staticmethod\n",
        "  def find_nearest_corner(location,bounds):\n",
        "\n",
        "    corner_lat_idx = np.argmin([\n",
        "        np.abs(bounds[0]-location[\"latitude\"]),\n",
        "        np.abs(bounds[1]-location[\"latitude\"])\n",
        "        ])\n",
        "\n",
        "    corner_lon_idx = np.argmin([\n",
        "        np.abs(bounds[2]-location[\"longitude\"]),\n",
        "        np.abs(bounds[3]-location[\"longitude\"])\n",
        "        ])\n",
        "\n",
        "    if (corner_lat_idx == 0) and (corner_lon_idx == 0):\n",
        "      # closests is latmin, lonmin\n",
        "      direction = \"southwest\"\n",
        "    elif (corner_lat_idx == 0) and (corner_lon_idx == 1):\n",
        "      direction = \"southeast\"\n",
        "    elif (corner_lat_idx == 1) and (corner_lon_idx == 0):\n",
        "      direction = \"northwest\"\n",
        "    else:\n",
        "      direction = \"northeast\"\n",
        "\n",
        "    corner_coords = (bounds[corner_lat_idx],bounds[corner_lon_idx+2])\n",
        "    return corner_coords, direction\n",
        "\n",
        "  @staticmethod\n",
        "  def get_ajoining_tiles(tx,ty,direction):\n",
        "\n",
        "    if direction == \"southwest\":\n",
        "      return [(tx-1,ty),(tx-1,ty+1),(tx,ty+1)]\n",
        "    elif direction == \"southeast\":\n",
        "      return [(tx+1,ty),(tx+1,ty-1),(tx,ty-1)]\n",
        "    elif direction == \"northwest\":\n",
        "      return [(tx-1,ty-1),(tx-1,ty),(tx,ty-1)]\n",
        "    else:\n",
        "      return [(tx+1,ty-1),(tx+1,ty),(tx,ty-1)]"
      ],
      "metadata": {
        "id": "K8TQatBqTtbS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(key=GOOGLE_MAPS_API_KEY)\n",
        "location = {\"longitude\":-118.3,\"latitude\":34.1}\n",
        "zoom = 7\n",
        "tiles = air_quality_tile(\n",
        "    client,\n",
        "    location,\n",
        "    pollutant=\"UAQI_INDIGO_PERSIAN\",\n",
        "    zoom=zoom,\n",
        "    get_adjoining_tiles=False)"
      ],
      "metadata": {
        "id": "hK9n7WVUTwyK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(key=GOOGLE_MAPS_API_KEY)\n",
        "location = {\"longitude\":-118.3,\"latitude\":34.1}\n",
        "zoom = 7\n",
        "tiles = air_quality_tile(\n",
        "    client,\n",
        "    location,\n",
        "    pollutant=\"UAQI_INDIGO_PERSIAN\",\n",
        "    zoom=zoom,\n",
        "    get_adjoining_tiles=False)"
      ],
      "metadata": {
        "id": "BjU1ZfbMTy6P"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}